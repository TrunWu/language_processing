{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC\n",
    "import re\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path1 = '../dataset/Tweets-airline-sentiment.csv'\n",
    "#data_path2 = '../dataset/labeledTrainData_head12000.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head()\n",
    "label = data['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "label_tags = label.unique()\n",
    "print(label_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace text label with one-hot-labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = []\n",
    "for l in label:\n",
    "    if l == label_tags[0]:\n",
    "        #new_label.append(np.array([0,0,1]))\n",
    "        new_label.append(0)\n",
    "    elif l == label_tags[1]:\n",
    "        #new_label.append(np.array([0,1,0]))\n",
    "        new_label.append(1)\n",
    "    else:\n",
    "        #new_label.append(np.array([1,0,0]))\n",
    "        new_label.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = np.asarray(new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of '@airline_company_name\n",
    "new_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in text:\n",
    "    t = re.sub('[0-9]', '', t)\n",
    "    new_text.append(re.sub('^@\\w+ *','', t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = np.asarray(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14640,), (14640,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text.shape, new_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x, y, n_split, test_train_split = 0.2):\n",
    "# x: traning test, in array\n",
    "#y: label\n",
    "#n_split: number of groups divided from x and y\n",
    "    if x.shape[0] != y.shape[0]:\n",
    "        raise('samples and their labels\\'number mismatched')\n",
    "    else:\n",
    "        instance_num = x.shape[0]\n",
    "        train_num = int(instance_num*(1-test_train_split))\n",
    "        permulated_arr = np.random.permutation(instance_num)\n",
    "        train_arr, test_arr = permulated_arr[:train_num], permulated_arr[train_num:]\n",
    "        train_each_num = int(train_num/n_split)\n",
    "        test_each_num = int((instance_num-train_num)/n_split)\n",
    "        for i in range(n_split):\n",
    "            if i == n_split-1:\n",
    "                #train index and test index\n",
    "                yield (train_arr[i*train_each_num:], test_arr[i*test_each_num:])\n",
    "            else:\n",
    "                yield (train_arr[i*train_each_num:(i+1)*train_each_num], test_arr[i*test_each_num:(i+1)*test_each_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'uni' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-65e4a99027a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muni\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'uni' is not defined"
     ]
    }
   ],
   "source": [
    "for train, test in split(uni, new_label,5):\n",
    "    print(train.shape)\n",
    "    print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB()\n",
    "pc = Perceptron()\n",
    "svm = LinearSVC()\n",
    "lr = LogisticRegression(solver='saga',max_iter=1000)\n",
    "random_forest  = rf()\n",
    "CNN = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = knn(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "HashVec = HashingVectorizer(n_features = 500, \n",
    "                         ngram_range=(1,1))\n",
    "Hash = HashVec.fit_transform(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7241813490056019\n",
      "0.726436031321512\n"
     ]
    }
   ],
   "source": [
    "for clf in [svm,lr]:\n",
    "    acc = []\n",
    "    for train_index, test_index in skf.split(Hash, new_label):\n",
    "        x_train,x_test = Hash[train_index], Hash[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TVec = TfidfVectorizer(ngram_range=(1,2), \n",
    "                       max_features=10000)\n",
    "T = TVec.fit_transform(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7900305260636258\n",
      "0.783058785247783\n"
     ]
    }
   ],
   "source": [
    "for clf in [svm, lr]:\n",
    "    acc = []\n",
    "    for train_index, test_index in skf.split(T, new_label):\n",
    "        x_train,x_test = T[train_index], T[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniVec = CountVectorizer(max_features = 9000, ngram_range = (1,2))\n",
    "uni = UniVec.fit_transform(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UniVec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = np.asarray(uni.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 9000)\n"
     ]
    }
   ],
   "source": [
    "#test where to see the data format\n",
    "print(uni.shape)\n",
    "#uni[122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 2, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix for SVM and LR based on Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion matrix \n",
    "svm_confusion_matrix = np.zeros((3,3))\n",
    "#'neutral' 0\n",
    "#'positive' 1\n",
    "#'negative' 2\n",
    "'''\n",
    "x coordinate would be predicted labels\n",
    "y coordinate would be true labels\n",
    "'''\n",
    "\n",
    "for clf in [svm]:\n",
    "    for train_index, test_index in skf.split(uni, new_label):\n",
    "        x_train,x_test = uni[train_index], uni[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "        for index, x_sample in enumerate(x_test):\n",
    "            true_label = y_test[index]\n",
    "            pred_label = pred[index]\n",
    "            svm_confusion_matrix[true_label, pred_label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_confusion = np.zeros_like(svm_confusion_matrix)\n",
    "for index, total in enumerate(np.sum(svm_confusion_matrix, axis=1)):\n",
    "    svm_confusion[index] = svm_confusion_matrix[index]/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53404324, 0.11648919, 0.34946757],\n",
       "       [0.14515446, 0.61362675, 0.24121879],\n",
       "       [0.08869035, 0.0343212 , 0.87698845]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_confusion_matrix = np.zeros((3,3))\n",
    "for clf in [lr]:\n",
    "    for train_index, test_index in skf.split(uni, new_label):\n",
    "        x_train,x_test = uni[train_index], uni[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        pred = clf.predict(x_test)\n",
    "        for index, x_sample in enumerate(x_test):\n",
    "            true_label = y_test[index]\n",
    "            pred_label = pred[index]\n",
    "            lr_confusion_matrix[true_label, pred_label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_confusion = np.zeros_like(lr_confusion_matrix)\n",
    "for index, total in enumerate(np.sum(lr_confusion_matrix, axis=1)):\n",
    "    lr_confusion[index] = lr_confusion_matrix[index]/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53662472, 0.10487254, 0.35850274],\n",
       "       [0.14261532, 0.60854846, 0.24883623],\n",
       "       [0.08498584, 0.029854  , 0.88516017]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unigram Models' Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in [lr]:\n",
    "    acc = []\n",
    "    for train_index, test_index in skf.split(uni, new_label):\n",
    "        x_train,x_test = uni[train_index], uni[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor clf in [ NB,pc, svm, lr]:\\n    acc = []\\n    for train_index, test_index in split(uni, new_label,5):\\n        x_train,x_test = uni[train_index], uni[test_index]\\n        y_train, y_test = new_label[train_index], new_label[test_index]\\n        clf.fit(x_train, y_train)\\n        acc.append(clf.score(x_test, y_test))\\n    acc = np.asarray(acc)\\n    print(acc.mean())\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use my split()\n",
    "'''\n",
    "for clf in [ NB,pc, svm, lr]:\n",
    "    acc = []\n",
    "    for train_index, test_index in split(uni, new_label,5):\n",
    "        x_train,x_test = uni[train_index], uni[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7343598569265384\n"
     ]
    }
   ],
   "source": [
    "for clf in [KNN,random_forest]:\n",
    "    acc = []\n",
    "    for train_index, test_index in skf.split(uni, new_label):\n",
    "        x_train,x_test = uni[train_index], uni[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7445391110264828\n"
     ]
    }
   ],
   "source": [
    "for clf in [CNN]:\n",
    "    acc = []\n",
    "    for train_index, test_index in skf.split(uni, new_label):\n",
    "        x_train,x_test = uni[train_index], uni[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "BiVec = CountVectorizer(max_features = 500, ngram_range = (2,2))\n",
    "Bi = BiVec.fit_transform(new_text)\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6745232666005136\n",
      "0.6002042115824728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6852469157471445\n",
      "0.6909827316494558\n",
      "0.5290298961422412\n",
      "0.6498645585559396\n"
     ]
    }
   ],
   "source": [
    "for clf in [NB, pc, svm, lr, KNN, random_forest]:\n",
    "    acc = []\n",
    "    for train_index, test_index in skf.split(Bi, new_label):\n",
    "        x_train,x_test = Bi[train_index], Bi[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6606575870982556\n"
     ]
    }
   ],
   "source": [
    "for clf in [CNN]:\n",
    "    acc = []\n",
    "    for train_index, test_index in skf.split(Bi, new_label):\n",
    "        x_train,x_test = Bi[train_index], Bi[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uni&Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "MixVec = CountVectorizer(max_features = 500, ngram_range = (1,2))\n",
    "Mix = BiVec.fit_transform(new_text)\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6745232666005136\n",
      "0.6002042115824728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6852469157471445\n",
      "0.6909827316494558\n",
      "0.5290298961422412\n",
      "0.6521880371253316\n"
     ]
    }
   ],
   "source": [
    "for clf in [NB, pc, svm, lr, KNN, random_forest]:\n",
    "    acc = []\n",
    "    for train_index, test_index in skf.split(Mix, new_label):\n",
    "        x_train,x_test = Mix[train_index], Mix[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6651650148139308\n"
     ]
    }
   ],
   "source": [
    "for clf in [CNN]:\n",
    "    acc = []\n",
    "    for train_index, test_index in skf.split(Mix, new_label):\n",
    "        x_train,x_test = Mix[train_index], Mix[test_index]\n",
    "        y_train, y_test = new_label[train_index], new_label[test_index]\n",
    "        clf.fit(x_train, y_train)\n",
    "        acc.append(clf.score(x_test, y_test))\n",
    "    acc = np.asarray(acc)\n",
    "    print(acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
